{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonEqui_mv_linear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super(NonEqui_mv_linear, self).__init__()\n",
    "        self.MV_dim = 16\n",
    "        \n",
    "        self.w = torch.randn(out_channels, in_channels, self.MV_dim)\n",
    "        self.bias = torch.randn(out_channels, self.MV_dim)\n",
    "\n",
    "        self.w = nn.Parameter(self.w)\n",
    "        self.bias = nn.Parameter(self.bias)\n",
    "\n",
    "        self.register_parameter(name=\"weight\", param=self.w)\n",
    "        self.register_parameter(name=\"bias\", param=self.bias)\n",
    "    def forward(self, x):\n",
    "\n",
    "        # expected x shape :\n",
    "        #[batch, seq_len, channels, mv_dim]\n",
    "        out = torch.einsum('b s c m, C c m -> b s C m', x, self.w)\n",
    "        \n",
    "        # add batch by broadcasting\n",
    "        out = out + self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 50, 4, 16)\n",
    "model = NonEqui_mv_linear(4, 8)\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 8, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 50, 4, 16)\n",
    "linear = NonEqui_mv_linear(in_channels=4, out_channels=4//2, batch=x.shape[0], seq_len=x.shape[1])\n",
    "params = [4, 4//2, x.shape[0], x.shape[1]]\n",
    "Q = NonEqui_mv_linear(*params)\n",
    "K = NonEqui_mv_linear(*params)\n",
    "V = NonEqui_mv_linear(*params)\n",
    "\n",
    "softmax = nn.functional.softmax\n",
    "\n",
    "# the multi_head proj ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 64])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim, n_head):\n",
    "        super(MultiHeadBlock, self).__init__()\n",
    "        \n",
    "        if emb_dim % n_head != 0:\n",
    "            raise ValueError(\"emb dim not compatible with n_head\")\n",
    "        self.input_size = emb_dim\n",
    "        self.n_head = n_head\n",
    "        self.head_dim = self.input_size // n_head\n",
    "\n",
    "        self.Q_layer = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.K_layer = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.V_layer = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "\n",
    "        self.softmax = nn.functional.softmax\n",
    "        self.multihead_projection = nn.Linear(emb_dim ,self.input_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input shape = [batch, seq_len, emb_dim]\n",
    "        \"\"\"\n",
    "        batch, seq_len = input.shape[0], input.shape[1]\n",
    "        # original x shape = [batch, seq_len, channels, 16]\n",
    "        #x = input.reshape(batch_size, seq_len, self.n_head, self.head_dim)\n",
    "        \n",
    "        x = x.permute(0, 2, 1, 3) #  [batch, seq_len, channels, emb_dim]\n",
    "        q, k, v = x.clone(), x.clone(), x.clone()\n",
    "\n",
    "        # out : batch, seq_len, channels, emb_dim\n",
    "        q = self.Q_layer(q)\n",
    "        k = self.K_layer(k)\n",
    "        v = self.V_layer(v)\n",
    "\n",
    "        # out batch channels seq_len, emb\n",
    "        k_T = k.permute(0, 2, 1, 3)\n",
    "        # old   # [batch, n_head, head_dim, seq_len]\n",
    "        #        k_T = k.permute(0, 1, 3, 2) \n",
    "\n",
    "        # self attention\n",
    "        # --------------\n",
    "        attention_w = self.softmax(torch.matmul(q, k_T)/self.head_dim**0.5, dim=-1)\n",
    "        attention_score = torch.matmul(attention_w, v) # [batch, n_head, seq_len, head_dim]\n",
    "\n",
    "        # come back to [batch, seq_len, n_head, emb_size]\n",
    "        attention_score = attention_score.permute(0, 2, 1, 3)\n",
    "\n",
    "        # squeeze to input shape\n",
    "        attention_score = attention_score.reshape(batch, seq_len, self.input_size)\n",
    "\n",
    "        # project to original input size\n",
    "        attention_out = self.multihead_projection(attention_score)\n",
    "\n",
    "        # combine attention and input = skipp connection\n",
    "        return attention_out + input\n",
    "\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, emb_dim, ffn_emb):\n",
    "        super(FullyConnected, self).__init__()\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(emb_dim, ffn_emb),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(ffn_emb, emb_dim),\n",
    "            nn.LayerNorm(emb_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.ffn(x)\n",
    "    \n",
    "# ---------------\n",
    "# test\n",
    "x = torch.randn(32, 4, 16)\n",
    "emb_size = 64\n",
    "transformer_block = nn.Sequential(\n",
    "    nn.Linear(16, emb_size), \n",
    "    MultiHeadBlock(emb_size,n_head=4),              # contains skipp connection\n",
    "    nn.LayerNorm(emb_size), \n",
    "    FullyConnected(emb_size, ffn_emb=emb_size*4),   # fully connected block + skipp connection \n",
    "    nn.LayerNorm(emb_size)\n",
    "    \n",
    ")\n",
    "transformer_block(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 4, 16)\n",
    "emb_size = 64\n",
    "\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, emb_dim, ffn_emb):\n",
    "        super(FullyConnected, self).__init__()\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.LayerNorm(emb_dim),\n",
    "            nn.Linear(emb_dim, ffn_emb),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(ffn_emb, emb_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.ffn(x)\n",
    "    \n",
    "\n",
    "transformer_block = nn.Sequential(\n",
    "    nn.Linear(16, emb_size),                      # project into latent dim\n",
    "    MultiHeadBlock(emb_size,n_head=4),            # multihead + skipp connection\n",
    "    FullyConnected(emb_size, ffn_emb=emb_size*4), # fully connected block + skipp connection \n",
    "    nn.LayerNorm(emb_size)\n",
    ")\n",
    "transformer_block(x)\n",
    "\n",
    "class NonEquivarTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_size, n_block=1):\n",
    "        \n",
    "        super(NonEquivarTransformer, self).__init__()\n",
    "\n",
    "        transformer_block = nn.Sequential(\n",
    "            nn.Linear(16, emb_size),                      # project into latent dim\n",
    "            MultiHeadBlock(emb_size,n_head=4),            # multihead + skipp connection\n",
    "            FullyConnected(emb_size, ffn_emb=emb_size*4), # fully connected block + skipp connection \n",
    "            nn.LayerNorm(emb_size)\n",
    "        )\n",
    "        self.transformer = nn.Sequential(\n",
    "            *[transformer_block for i in range(n_block)]  # -> *[] unpack the list \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(emb_size, 1), \n",
    "            # nn.Sigmoid() --> not used, just return logit : numerical stability in the loss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1) # mean pooling across the seq_len dim\n",
    "        y = self.classifier(x)\n",
    "        return y\n",
    "\n",
    "classifier = NonEquivarTransformer(emb_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NonEquivarTransformer(\n",
       "  (transformer): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (1): MultiHeadBlock(\n",
       "        (Q_layer): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (K_layer): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (V_layer): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (multihead_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): FullyConnected(\n",
       "        (ffn): Sequential(\n",
       "          (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7776],\n",
       "        [-6.4134],\n",
       "        [ 6.6611],\n",
       "        [-6.5333],\n",
       "        [ 6.7147],\n",
       "        [-6.3710],\n",
       "        [-6.3725],\n",
       "        [-6.2817],\n",
       "        [-6.4525],\n",
       "        [-6.4585],\n",
       "        [-6.7606],\n",
       "        [ 6.7850],\n",
       "        [-6.3850],\n",
       "        [ 6.3662],\n",
       "        [-6.3539],\n",
       "        [-6.5630],\n",
       "        [-6.7570],\n",
       "        [-6.7158],\n",
       "        [ 6.3337],\n",
       "        [ 6.8090],\n",
       "        [ 6.2347],\n",
       "        [ 6.5377],\n",
       "        [ 6.4298],\n",
       "        [-6.4829],\n",
       "        [ 6.5602],\n",
       "        [-6.6577],\n",
       "        [ 6.2722],\n",
       "        [-6.7036],\n",
       "        [ 6.3142],\n",
       "        [ 6.4708],\n",
       "        [-6.7307],\n",
       "        [-6.6444]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "y = torch.randint(high=2, size=(y_hat.shape[0],)).reshape(y_hat.shape).to(torch.float32)\n",
    "optimizer = torch.optim.Adam(classifier.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    y_hat = classifier(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9989],\n",
       "        [0.0016],\n",
       "        [0.9987],\n",
       "        [0.0015],\n",
       "        [0.9988],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0019],\n",
       "        [0.0016],\n",
       "        [0.0016],\n",
       "        [0.0012],\n",
       "        [0.9989],\n",
       "        [0.0017],\n",
       "        [0.9983],\n",
       "        [0.0017],\n",
       "        [0.0014],\n",
       "        [0.0012],\n",
       "        [0.0012],\n",
       "        [0.9982],\n",
       "        [0.9989],\n",
       "        [0.9980],\n",
       "        [0.9986],\n",
       "        [0.9984],\n",
       "        [0.0015],\n",
       "        [0.9986],\n",
       "        [0.0013],\n",
       "        [0.9981],\n",
       "        [0.0012],\n",
       "        [0.9982],\n",
       "        [0.9985],\n",
       "        [0.0012],\n",
       "        [0.0013]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.sigmoid(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.001\n",
    "    \n",
    "    emb_size: int =     64 # projection dim for equilinear layer\n",
    "\n",
    "\n",
    "class ClassifierLightning(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(ClassifierLightning, self).__init__()\n",
    "        self.emb_size = params.emb_size\n",
    "        self.lr = params.learning_rate\n",
    "        self.batch_size = params.batch_size\n",
    "\n",
    "        self.model = NonEquivarTransformer(emb_size=emb_size)\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.model(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)  # call the forward\n",
    "        self.criterion(y_hat, y.view(-1, 1))\n",
    "        self.log(\"train loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)  # call the forward\n",
    "        self.criterion(y_hat, y.view(-1, 1))\n",
    "        self.log(\"val loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "light_model = ClassifierLightning(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/dema/Project/GAT/src/Transformer_standard/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | model     | NonEquivarTransformer | 50.9 K\n",
      "1 | criterion | BCEWithLogitsLoss     | 0     \n",
      "----------------------------------------------------\n",
      "50.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.9 K    Total params\n",
      "0.204     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b258124d20824b4aab28878b2f2ce0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dema/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ClassifierLightning.validation_step() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlight_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Project/GAT/.venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ClassifierLightning.validation_step() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "x_train = torch.rand(32, 4, 16)  # 100 samples\n",
    "y_train = (torch.rand(32) > 0.5).float()  # Binary labels\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "x_val = torch.rand(32, 4, 16)  # Validation data\n",
    "y_val = (torch.rand(32) > 0.5).float()  # Binary labels\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "    # Define trainer\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "\n",
    "    # Fit the model\n",
    "trainer.fit(light_model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
